{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /Users/gbenz/Documents/FEWSnet\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "os.chdir('/Users/gbenz/Documents/FEWSnet')\n",
    "print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "from Utils.api_ipc_request import construct_ipc_api_url\n",
    "from Utils.api_boundary_request import construct_boundary_api_url\n",
    "from Utils.temporal_coverage import plot_fewsnet_scenario_coverage\n",
    "from Utils.countries_to_process import select_country_codes\n",
    "from Utils.check_shapefile import pg_shapefile_exists\n",
    "from Utils.input_base_requirements import get_date_range, select_ipc_classification\n",
    "\n",
    "# Feature Engineering\n",
    "from Utils.filter_tables import desirable_attributes\n",
    "from Utils.merge_and_report import merge_ipc_with_boundaries, evaluate_merge_completness\n",
    "from Utils.scenario import define_scenario\n",
    "\n",
    "# Plot\n",
    "from Utils.plot_ipc_orig_boundaries import plot_historical_ipc\n",
    "\n",
    "# Load PG\n",
    "from Utils.give_PG_reference import provide_reference_frame\n",
    "\n",
    "\n",
    "#Compute area features\n",
    "from Utils.area_attributes import define_area_attributes\n",
    "\n",
    "\n",
    "#Perform Intersection\n",
    "from Utils.perform_intersection import intersect\n",
    "from Utils.build_envelope import envelope_buffer\n",
    "\n",
    "\n",
    "#Define process to conver FEWSNET to PG\n",
    "from Utils.select_process import define_process\n",
    "from Utils.user_process_selection import get_process_selection\n",
    "\n",
    "\n",
    "#Rejoin data to PG shapefile (GPD)\n",
    "from Utils.rejoin_pg_data import rejoin_to_pg\n",
    "\n",
    "from Utils.cumulative_population_attribution import engineer_population_attributes\n",
    "from Utils.pg_country_extent import create_country_geodataframe\n",
    "from Utils.leftjoin_to_pg_country import left_join_geodataframes\n",
    "from Utils.select_dates import get_dates_to_process\n",
    "\n",
    "# Save the data\n",
    "from Utils.csv_naming_conventions import apply_naming_convention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#project_root = Path(__file__).resolve()\n",
    "\n",
    "# Designate a local path:\n",
    "csv_path = '/Users/gbenz/Documents/FEWSnet/Data/Processed/csv/FEWSnet_to_PG_'\n",
    "print(f'The final csv result will be saved to path: {csv_path}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process to define historical data for ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "if pg_shapefile_exists():\n",
    "    print(\"The PG reference shapefile has already been produced!\")\n",
    "else:\n",
    "    print(\n",
    "    \"The PG Shapefile does not exist. This process must be completed before integrating FEWSNET data.\\n\"\n",
    "    \"I will produce and save the PG reference file now. Once complete, it can be accessed in Data/Processed/extent_shapefile/\"\n",
    "    )\n",
    "    \n",
    "    provide_reference_frame()\n",
    "\n",
    "ipc_classification = select_ipc_classification()\n",
    "s, e = get_date_range()\n",
    "ipc = construct_ipc_api_url(s, e, ipc_classification)\n",
    "print(list(ipc))\n",
    "#Print all country_codes:\n",
    "#country_code_list = sorted(ipc['country_code'].unique().tolist())\n",
    "\n",
    "ipc_country, selected_country_codes = select_country_codes(ipc)\n",
    "\n",
    "endyear = int(e.split('-')[0])\n",
    "\n",
    "icp_country_result = plot_fewsnet_scenario_coverage(ipc, endyear)\n",
    "\n",
    "process_selection = get_process_selection()\n",
    "\n",
    "all_country_results = []\n",
    "\n",
    "for country_code in selected_country_codes:\n",
    "\n",
    "    # identify country associated with country code:\n",
    "\n",
    "    country_name = ipc.loc[ipc['country_code'] == country_code, 'country'].iloc[0]\n",
    "\n",
    "    print(f\"Processing country: {country_code} ({country_name})\")\n",
    "\n",
    "    boundaries = construct_boundary_api_url(country_code)\n",
    "\n",
    "    ipc_filtered, spatial_filtered = desirable_attributes(ipc_country, boundaries)\n",
    "\n",
    "    merge, unmatched = merge_ipc_with_boundaries(ipc_filtered, spatial_filtered)\n",
    "\n",
    "    evaluate_merge_completness(merge, ipc_filtered, unmatched)\n",
    "\n",
    "    scenario = define_scenario(merge)\n",
    "\n",
    "    merged_df_current = gpd.GeoDataFrame(scenario, geometry='geometry')\n",
    "\n",
    "    plot_historical_ipc(merged_df_current)\n",
    "\n",
    "    result_dfs = []\n",
    "\n",
    "    # Get unique dates from the dataset\n",
    "    dataset_dates = sorted(merged_df_current['reporting_date'].unique().tolist())\n",
    "    print(dataset_dates)\n",
    "\n",
    "    dates_to_process = get_dates_to_process(dataset_dates)\n",
    "\n",
    "    # Loop through each date in the dataset_dates\n",
    "    for i, processing_date in enumerate(dates_to_process):  # Enumerate gives both index and value\n",
    "        print()\n",
    "        print(f\"Processing date: {processing_date}\")\n",
    "        print()\n",
    "\n",
    "        # Extract the year from the current processing date\n",
    "        year = processing_date.split('-')[0]\n",
    "        year_int = int(processing_date.split('-')[0])\n",
    "\n",
    "        # Filter the dataset for the current date\n",
    "        merged_df_current_lim = merged_df_current[merged_df_current['reporting_date'] == processing_date]\n",
    "\n",
    "        # Generate a buffered envelope for the filtered dataset\n",
    "        envelope_gdf_buffered = envelope_buffer(merged_df_current_lim, distance=25000)\n",
    "\n",
    "        # Ensure only valid geometry types\n",
    "        merged_df_current_lim = merged_df_current_lim[merged_df_current_lim.geom_type.isin(['Polygon', 'MultiPolygon'])]\n",
    "\n",
    "        # Perform the intersection\n",
    "        intersected_gdf = intersect(merged_df_current_lim)\n",
    "\n",
    "        # Ensure area attributes are defined\n",
    "        intersected_gdf = define_area_attributes(intersected_gdf)\n",
    "\n",
    "        # Check if the selected process requires population data\n",
    "        if process_selection in [5, 6]:\n",
    "            intersected_gdf = engineer_population_attributes(year, country_code, intersected_gdf, envelope_gdf_buffered)\n",
    "\n",
    "        # Define the process and generate the result\n",
    "        result = define_process(process_selection, intersected_gdf)\n",
    "\n",
    "        # Rejoin the result to the priogrid\n",
    "        # Applies the data frame containing a pg attribute to the spatial pg extent\n",
    "        result_gdf = rejoin_to_pg(result)\n",
    "        \n",
    "        # Add processing_date and country_code fields to result_gdf\n",
    "        result_gdf['processing_date'] = processing_date\n",
    "        result_gdf['country_code'] = country_code\n",
    "\n",
    "        # Trim results to PG (viewser defined) country extent\n",
    "        gpd_country_extent_df = create_country_geodataframe(country_name, year_int, shapefile_path=None)\n",
    "        \n",
    "        print()\n",
    "        print('Fields in DF2')\n",
    "        print(list(result_gdf))\n",
    "        print()\n",
    "        print('Fields in DF1')\n",
    "        print(list(gpd_country_extent_df))\n",
    "        print()\n",
    "\n",
    "        country_joined=left_join_geodataframes(gpd_country_extent_df, result_gdf)\n",
    "\n",
    "        # Append the result_gdf to the list\n",
    "        result_dfs.append(country_joined)\n",
    "\n",
    "        print(f\"Completed processing for {processing_date}. Result saved.\")\n",
    "\n",
    "    # Concatenate the results for the current country\n",
    "    country_result_df = pd.concat(result_dfs, ignore_index=True)\n",
    "\n",
    "    # Check if 'final_weighted_value' exists before renaming\n",
    "    if 'final_weighted_value' in country_result_df.columns:\n",
    "        country_result_df = country_result_df.rename(columns={'final_weighted_value': 'IPC_value'})\n",
    "\n",
    "    # Check if 'original_sum_value' exists before dropping\n",
    "    if 'original_sum_value' in country_result_df.columns:\n",
    "        country_result_df = country_result_df.drop(columns=['original_sum_value'])\n",
    "\n",
    "    # Append to the all-country results list\n",
    "    all_country_results.append(country_result_df)\n",
    "\n",
    "# Concatenate results for all countries\n",
    "final_result_df = pd.concat(all_country_results, ignore_index=True)\n",
    "\n",
    "# Naming Conventions:\n",
    "naming_conventions = apply_naming_convention(dates_to_process, selected_country_codes, process_selection)\n",
    "\n",
    "csv_path_with_naming = csv_path.with_name(csv_path.name + naming_conventions + '.csv')\n",
    "\n",
    "# The final_result_df now contains data for all countries and dates\n",
    "final_result_df.to_csv(csv_path_with_naming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Utils.pg_country_extent import create_country_geodataframe\n",
    "\n",
    "country_name = 'Ethiopia'\n",
    "year = 2022\n",
    "\n",
    "gpd_df = create_country_geodataframe(country_name, year, shapefile_path=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import geopandas as pgd \n",
    "from ingester3.extensions import *\n",
    "\n",
    "gpd_df = gpd.read_file('Data/Processed/extent_shapefile/pg_viewser_extent.shp')\n",
    "\n",
    "new_country_year = pd.DataFrame.cy.new_africa(max_year=2020) # year + 1\n",
    "new_country_year['name'] = new_country_year.c.name\n",
    "print(new_country_year)\n",
    "\n",
    "countries = sorted(pd.unique(new_country_year['name'].tolist()))\n",
    "print(countries)\n",
    "\n",
    "\n",
    "filtered_df = new_country_year[(new_country_year['name'] == 'Ethiopia') & (new_country_year['year_id'] == 2020)]\n",
    "print(filtered_df)\n",
    "\n",
    "filtered_df_pg=filtered_df.cy.pg_id\n",
    "\n",
    "print(list(filtered_df_pg))\n",
    "\n",
    "merged_df = pd.merge(filtered_df_pg, gpd_df, on='pg_id', how='inner')  # Default join is inner\n",
    "print(list(merged_df))\n",
    "\n",
    "\n",
    "# Assuming `df` is your DataFrame\n",
    "if 'geometry' in merged_df.columns:\n",
    "    # Convert to GeoDataFrame\n",
    "    gdf = gpd.GeoDataFrame(merged_df, geometry=merged_df['geometry'])\n",
    "\n",
    "    # Ensure CRS is set\n",
    "    if gdf.crs is None:\n",
    "        gdf.set_crs(\"EPSG:4326\", inplace=True)  # Assuming WGS84 CRS (latitude/longitude)\n",
    "\n",
    "    print(\"Conversion to GeoDataFrame successful!\")\n",
    "    print(gdf.head())  # Display the first few rows\n",
    "else:\n",
    "    print(\"Error: 'geometry' column not found in the DataFrame.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gdf['c_id'] = gdf.pgy.c_id\n",
    "\n",
    "#c_d.cy.pg_id\n",
    "import pandas as pd\n",
    "from ingester3 import *\n",
    "df_with_cid = pd.DataFrame.c.from_pg(intersected_gdf, pg_col='pg_id')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "viewser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
